{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Derin Öğrenme İle Toprak Sınıflandırma\n",
    "\n",
    "Zeminlerin sınıflandırılması, geoteknik mühendisliği, ziraat bilimi ve inşaat dahil olmak üzere birçok alanda önemli bir yetenek olabilir.\n",
    "Birçok sınıflandırma şeması mevcut olmakla birlikte, toprakları sınıflandırmanın popüler ve sezgisel bir yolu, çakıl, silt, kum vb. gibi toprak tane boyutuna dayanmaktadır. Bu, toprağı sınıflandırmanın oldukça basit bir yoludur çünkü her sınıflandırma arasında kesin sınırlar vardır. Örneğin, çakıl çapı 2 mm'den büyük herhangi bir tanedir, kum  $\\frac{1}{16}$ mm ile 2 mm arasında, ve silt/kil  $\\frac{1}{16}$ mm'den daha küçüktür.\n",
    "\n",
    "<img align=left width=400px src='https://apmonitor.com/pds/uploads/Main/soil_classification.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amaç\n",
    "Bu alıştırmada bilgisayar görüşü, çakıl, kum ve silt fotoğraflarına dayalı olarak zeminlerin bir sınıflandırma modelini yapar. Toprağın fotoğraflarını sınıflandırmak için evrişimli bir sinir ağı çerçevesi kullanılmıştır.\n",
    "\n",
    "### Anahtar kavramlar:\n",
    "#### Veri Büyütme\n",
    "Veri Büyütme, mevcut verilerden yeni veri kümeleri oluşturarak mevcut görüntü veri kümesini büyüten, görüntü sınıflandırmada yaygın olarak kullanılan bir uygulamadır. Bu büyütme en çok görüntüyü kaydırma, görüntüyü yatay veya dikey olarak yansıtma, görüntüyü yakınlaştırma vb. işlemlerde görülür. Bu büyütmeler daha sonra yeni görüntüler oluşturur ve böylece üzerinde çalışılacak görüntü sayısını artırır. Bu konuda daha fazla bilgi edinmek için okuyun [article from Jason Brownlee](https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/).\n",
    "\n",
    "#### Evrişimsel Sinir Ağı (CNN)\n",
    "Bir evrişimli sinir ağı (CNN), görüntü sınıflandırması için popüler bir modeldir. CNN'ler, bir görüntüdeki piksel değerleri arasında dolaşarak ve bir filtre \"çekirdek\" matrisi ile bu piksellerin nokta çarpımını hesaplayarak bir görüntünün özelliklerini ayırt eder. Bu çekirdek matrisleri, görüntünün dikey ve yatay çizgiler, eğrilik vb. gibi farklı yönlerini vurgular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_directory = 'train'\n",
    "test_data_directory = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kurulum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aşağıdaki Python modüllerini içe aktarın. Eksik paketleri kurmak için ```pip``` kullanmayı unutmayın. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yF35Ku0Ms-O6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import time\n",
    "import shutil\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from random import randrange\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veri\n",
    "\n",
    "Veriler, test ve eğitim dizinlerine ayrılır. Test klasörü ve tren klasörü, olası kirlere karşılık gelen alt dizinleri içerir. Klasörlerin etiketli ağaç yapısı, eğitim ve test için fotoğrafların işaretlenmesine yardımcı olur."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "├───test\n",
    "│   ├───Gravel\n",
    "│   ├───Sand\n",
    "│   └───Silt\n",
    "└───train\n",
    "    ├───Gravel\n",
    "    ├───Sand\n",
    "    └───Silt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soil_photos.zip Veri İndirme\n",
    "file = 'soil_photos.zip'\n",
    "url = 'http://apmonitor.com/pds/uploads/Main/'+file\n",
    "urllib.request.urlretrieve(url, file)\n",
    "\n",
    "# soil_photos.zip Arşivini dışarı aktarıp zip dosyasının silinmesi\n",
    "with zipfile.ZipFile(file, 'r') as zip_ref:\n",
    "    zip_ref.extractall('./')\n",
    "os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verileri Python oturumuna aktarın. İlk adım, görüntüleri bir formata dönüştürmektir 1) verileri model için okunabilir hale getirir, ve 2) modelin öğrenmesi için daha fazla eğitim materyali sağlar. Örneğin, \"training_data_processor\" değişkeni, verileri bir model girdisi olacak şekilde ölçeklendirir, ancak aynı zamanda her bir görüntüyü alır ve modelin aynı resmin birden çok varyasyonundan öğrenebilmesi için onu büyütür. Modelin yön veya boyuttan ziyade toprak fotoğrafından öğrenmesi için yatay olarak çevirir, döndürür, kaydırır ve daha fazlasını yapar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23726,
     "status": "ok",
     "timestamp": 1618065873113,
     "user": {
      "displayName": "Peter Van Katwyk",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhknOaA2vSO9txrYBB1U01ff4hmNe3wj5xrjP9Nzg=s64",
      "userId": "16032387266776692701"
     },
     "user_tz": 360
    },
    "id": "topbCwEWsr3q",
    "outputId": "a4116caa-a435-41f2-d2d8-71ca1e307d8c"
   },
   "outputs": [],
   "source": [
    "# Veri işleme araçlarını tanımlıyoruz\n",
    "training_data_processor = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    horizontal_flip = True,\n",
    "    zoom_range = 0.2,\n",
    "    rotation_range = 10,\n",
    "    shear_range = 0.2,\n",
    "    height_shift_range = 0.1,\n",
    "    width_shift_range = 0.1\n",
    ")\n",
    "\n",
    "test_data_processor = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# Verileri içeri alıyoruz \n",
    "training_data = training_data_processor.flow_from_directory(\n",
    "    training_data_directory,\n",
    "    target_size = (256, 256),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical',\n",
    ")\n",
    "\n",
    "testing_data = test_data_processor.flow_from_directory(\n",
    "    test_data_directory,\n",
    "    target_size = (256 ,256),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Oluşturma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN modelini oluşturun. Aşağıdaki hücre, model oluşturma için parametreleri ayarlar. Bu, evrişimli katmanların sayısını, tam bağlantılı yoğun katmanları, her katmandaki düğüm sayısını ve eğitim dönemlerinin sayısını içerir. \"layer_size\" parametresinin modelin eğitim hızı, doğruluğu ve boyutu üzerinde büyük etkisi vardır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3288116,
     "status": "ok",
     "timestamp": 1618026147600,
     "user": {
      "displayName": "Peter Van Katwyk",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhknOaA2vSO9txrYBB1U01ff4hmNe3wj5xrjP9Nzg=s64",
      "userId": "16032387266776692701"
     },
     "user_tz": 360
    },
    "id": "9-jCm9Y3Ehbs",
    "outputId": "c99cfeb8-dd44-4da7-e0b7-e97ba1455875"
   },
   "outputs": [],
   "source": [
    "# model parametrelerini seç\n",
    "num_conv_layers = 2\n",
    "num_dense_layers = 1\n",
    "layer_size = 32\n",
    "num_training_epochs = 20\n",
    "MODEL_NAME = 'soil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model değişkenini başlat\n",
    "model = Sequential()\n",
    "\n",
    "# model değişkenine özellikler ekliyoruz\n",
    "model.add(Conv2D(layer_size, (3, 3), input_shape=(256,256, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# num_conv_layers'a dayalı ek evrişim katmanları ekleyoruz\n",
    "for _ in range(num_conv_layers-1):\n",
    "    model.add(Conv2D(layer_size, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# boyutsallığı azaltıyoruz\n",
    "model.add(Flatten())\n",
    "\n",
    "# belirtilmişse tamamen bağlı \"yoğun\" katmanlar ekliyoruz\n",
    "for _ in range(num_dense_layers):\n",
    "    model.add(Dense(layer_size))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "# çıkış layerını ayarlıyoruz\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# tüm eklenen özelliklerle sıralı modeli derliyoruz\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'],\n",
    "                )\n",
    "\n",
    "# modeli eğitmek/ayarlamak için yüklenmiş verileri kullanıyoruz\n",
    "model.fit(training_data,\n",
    "            epochs=num_training_epochs,\n",
    "            validation_data = testing_data)\n",
    "\n",
    "# eğitilmiş modeli kaydediyoruz\n",
    "model.save(f'{MODEL_NAME}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Test Aşaması"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model artık eğitilmiş ve bilgisayara kaydedilmiştir (bu not defteri ile aynı klasörde). Yukarıdaki yazdırılan çıktının son satırı, hem eğitim verilerinin hem de doğrulama veya test verilerinin doğruluğunu içerir. Modelin eğitilmediği görüntülerdeki doğruluğa karşılık gelen son satırdaki ``val_accuracy`` değerine dikkat edin. Bu, diğer görüntülerdeki tahmin edici performansının en iyi ölçüsüdür.\n",
    "\n",
    "Aşağıdaki işlev olan ``make_prediction``, girdi olarak bir zemin fotoğrafına giden dosya yolunu alır ve modelin öngördüğü sınıflandırmayı verir. Test klasöründen, dosya yolunu ikinci hücredeki test_image_filepath değişkenine kopyalayın. Birkaç fotoğraf deneyin ve modelin nasıl oluştuğunu görün. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "executionInfo": {
     "elapsed": 3080,
     "status": "ok",
     "timestamp": 1617992171243,
     "user": {
      "displayName": "Peter Van Katwyk",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhknOaA2vSO9txrYBB1U01ff4hmNe3wj5xrjP9Nzg=s64",
      "userId": "16032387266776692701"
     },
     "user_tz": 360
    },
    "id": "Chpl4ZrSPtHc",
    "outputId": "cb9bd334-7945-4a5d-d765-6abd8f0f0eec",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_prediction(image_fp):\n",
    "    im = cv2.imread(image_fp) # resim yüklüyoruz\n",
    "    plt.imshow(im[:,:,[2,1,0]])\n",
    "    img = image.load_img(image_fp, target_size = (256,256))\n",
    "    img = image.img_to_array(img)\n",
    "\n",
    "    image_array = img / 255. # resmi ölçeklendiriyoruz\n",
    "    img_batch = np.expand_dims(image_array, axis = 0)\n",
    "    \n",
    "    class_ = [\"Gravel\", \"Sand\", \"Silt\"] # çıkış değerleri tanımlıyoruz\n",
    "    predicted_value = class_[model.predict(img_batch).argmax()]\n",
    "    true_value = re.search(r'(Gravel)|(Sand)|(Silt)', image_fp)[0]\n",
    "    \n",
    "    out = f\"\"\"Predicted Soil Type: {predicted_value}\n",
    "    True Soil Type: {true_value}\n",
    "    Correct?: {predicted_value == true_value}\"\"\"\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_image_filepath = test_data_directory + r'/Sand/0.jpg'\n",
    "print(make_prediction(test_image_filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zemin Sınıflandırma Yüzdeleri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topraklar tam olarak homojen değildir (hepsi bir toprak tipi). Topraklar genellikle türlerin bir karışımıdır ve yüzde kullanılarak daha iyi temsil edilebilir. Örneğin, aşağıdaki hücrede \"Silt\" etiketli bir test fotoğrafı gösterilmektedir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "percentage_photo = test_data_directory + r\"/Silt/5.jpg\"\n",
    "im = cv2.imread(percentage_photo) # Test etmek için fotoğrafı içeri aktarıyoruz\n",
    "plt.imshow(im[:,:,[2,1,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu fotoğrafta biraz çakıl var, ancak tek bir fotoğrafta kum, çakıl ve silt var gibi görünüyor. Bu görüntüyü daha iyi sınıflandırmak için her etiketin bir oranını oluşturun. Örneğin, bu fotoğraf %30 Çakıl, %20 Kum ve %50 Silt olabilir.\n",
    "\n",
    "Fotoğrafı birçok küçük parçaya veya kareye bölün ve daha küçük kareler üzerinde bir sınıflandırıcı eğitin. Her küçük kareyi sınıflandırmak için fotoğrafta gezinin ve Çakıl, Kum ve Silt ile ilgili karelerin bir oranını alın. Bu oran daha sonra ilgili toprak tipinin bir yüzdesine dönüştürülür."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mevcut eğitim fotoğraflarını daha küçük bölümlere ayırmak için aşağıdaki hücreleri çalıştırın. Yeni dizin, train_divided ve test_divided olarak adlandırılacaktır.  \n",
    "\n",
    "Not: Bu biraz zaman alacaktır (~30 saniye ile 2 dakika arası)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_images(image_dir, save_dir):\n",
    "    classification_list = ['Gravel', 'Sand', 'Silt']\n",
    "    for classification in classification_list:\n",
    "        folder = image_dir + '/' + classification + '/'\n",
    "        save_folder = save_dir + '/' + classification + '/'\n",
    "        files = [f for f in listdir(folder) if isfile(join(folder, f))]\n",
    "\n",
    "        for file in files:\n",
    "            if '.ini' in file:\n",
    "                continue\n",
    "            fp = folder + file\n",
    "            img = cv2.imread(fp)\n",
    "            h,w,c = img.shape\n",
    "            im_dim = 64\n",
    "            # Görüntüleri kırpıyoruz\n",
    "            for r in range(0,img.shape[0],im_dim):\n",
    "                for c in range(0,img.shape[1],im_dim):\n",
    "                    cropped_img = img[r:r+im_dim, c:c+im_dim,:]\n",
    "                    ch, cw, cc = cropped_img.shape\n",
    "                    if ch == im_dim and cw == im_dim:\n",
    "                        write_path = f\"{save_folder + str(randrange(100000))}img{r}_{c}.jpg\"\n",
    "                        cv2.imwrite(write_path,cropped_img)\n",
    "                    else:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    parent = training_data_directory.replace('train', '')\n",
    "    dirs = ['train_divided', 'test_divided']\n",
    "    class_ = [\"Gravel\", \"Sand\", \"Silt\"]\n",
    "    for dir in dirs:\n",
    "        os.mkdir(os.path.join(parent, dir))\n",
    "        for classification in class_:\n",
    "            os.mkdir(os.path.join(parent, dir, classification))\n",
    "\n",
    "    # kırpılmış eğitim görüntüleri\n",
    "    split_images(image_dir=training_data_directory,\n",
    "                save_dir=training_data_directory.replace('train', 'train_divided'))\n",
    "    # kırpılmış test görüntüleri\n",
    "    split_images(image_dir=test_data_directory,\n",
    "                save_dir=test_data_directory.replace('test', 'test_divided'))\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Yükleme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giriş piksellerinin sayısı değişirse, yeni bir model eğitilmelidir veya görüntü orijinal eğitim boyutlarına yeniden ölçeklendirilmelidir. Bu demonun amaçları doğrultusunda, her görüntüde 256x256 blok (16) alt örneklemeden önce fotoğraflar 1024x1024'e yükseltildiğinden yeniden eğitim gerekli değildir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fp = os.getcwd()+'/'+'soil.h5'\n",
    "print(model_fp)\n",
    "model = load_model(model_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Görüntü Sınıflandırma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bir test görüntüsünü sınıflandırmak için yüklenen modeli kullanın. 'classify_images' işlevi bir görüntü ve bir model alır ve her 256x256 karede döngü yapar. Her kareyi sınıflandırır ve kesirli toprak tahmini oluşturmak için sayaca ekler. İşlev, sınıflandırılan her toprak tipinin oranını verir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_images(image_fp, model):\n",
    "    classes = ['Gravel', 'Sand', 'Silt']\n",
    "    gravel_count = 0\n",
    "    sand_count = 0\n",
    "    silt_count = 0\n",
    "\n",
    "    img = cv2.imread(image_fp)\n",
    "    img = cv2.resize(img,(1024,1024))\n",
    "    im_dim = 256\n",
    "\n",
    "    for r in range(0, img.shape[0], im_dim):\n",
    "        for c in range(0, img.shape[1], im_dim):\n",
    "            cropped_img = img[r:r + im_dim, c:c + im_dim, :]\n",
    "            h, w, c = cropped_img.shape\n",
    "            if h == im_dim and w == im_dim:\n",
    "                classification = model_classify(cropped_img, model)\n",
    "                if classification == classes[0]:\n",
    "                    gravel_count += 1\n",
    "                elif classification == classes[1]:\n",
    "                    sand_count += 1\n",
    "                elif classification == classes[2]:\n",
    "                    silt_count += 1\n",
    "            else:\n",
    "                continue\n",
    "    total_count = gravel_count + sand_count + silt_count\n",
    "    proportion_array = [gravel_count / total_count, sand_count / total_count, silt_count / total_count]\n",
    "    return proportion_array\n",
    "\n",
    "\n",
    "def model_classify(cropped_img, model):\n",
    "    classes = ['Gravel', 'Sand', 'Silt']\n",
    "    image_array = cropped_img / 255.\n",
    "    img_batch = np.expand_dims(image_array, axis=0)\n",
    "    prediction_array = model.predict(img_batch)[0]\n",
    "    first_idx = np.argmax(prediction_array)\n",
    "    first_class = classes[first_idx]\n",
    "    return first_class\n",
    "\n",
    "def classify_percentage(image_fp):\n",
    "    start = time.time()\n",
    "    out = classify_images(image_fp=image_fp, model=model)\n",
    "    finish = str(round(time.time() - start, 5))\n",
    "    \n",
    "    im = cv2.imread(image_fp) # load image\n",
    "    plt.imshow(im[:,:,[2, 1, 0]])\n",
    "\n",
    "    print(f'''---\n",
    "Çakıl Yüzdesi: {round(out[0] * 100, 2)}%)\n",
    "Kum Yüzdesi: {round(out[1] * 100, 2)}%)\n",
    "Silt Yüzdesi: {round(out[2] * 100, 2)}%)\n",
    "Sınıflandırma Zamanı: {finish} seconds\n",
    "---''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_percentage(image_fp=percentage_photo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yüzde sınıflandırılmış fotoğrafla eşleşiyor mu? Toprak sınıflandırmasına yönelik her iki yaklaşımın da avantajları vardır. Örneğin, tüm görüntüyü sınıflandırmak daha hızlıdır. Bununla birlikte, yüzde sınıflandırması hesaplama açısından daha pahalıdır ancak daha fazla bilgi sağlar ve gerçek sınıflandırmanın daha iyi bir temsili olabilir."
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyNhoK7FQHGoNgSPJqWd8qt+",
   "collapsed_sections": [],
   "name": "SoilClassification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
